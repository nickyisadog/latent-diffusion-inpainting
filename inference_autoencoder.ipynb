{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ff1a600",
   "metadata": {},
   "source": [
    "# This notebook is an example notebook to inference autoencdoer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae80fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse, os, sys, glob\n",
    "sys.path.append(os.getcwd()+\"/ldm\")\n",
    "from omegaconf import OmegaConf\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "from ldm.ldm.util import instantiate_from_config\n",
    "from ldm.ldm.models.diffusion.ddim import DDIMSampler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as T\n",
    "transform = T.ToPILImage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e03b13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "yaml_path = \"./ldm/models/first_stage_models/vq-f4-noattn/config.yaml\"\n",
    "data_path = \"./splits/test/images\"\n",
    "ckpt_path = \"./ldm/models/first_stage_models/vq-f4-noattn/auto.ckpt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92c7985",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Image_dataset(Dataset):\n",
    "    def __init__(self, size, data_root, config=None):\n",
    "        self.size = size\n",
    "        self.data_root=data_root\n",
    "        self.image_list = []\n",
    "        \n",
    "        for image in os.listdir(data_root):\n",
    "            self.image_list.append(data_root+\"/\"+image)\n",
    "                        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_list)\n",
    "\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "\n",
    "        image = np.array(Image.open(self.image_list[i]).convert(\"RGB\").resize((self.size,self.size)))\n",
    "        image = image.astype(np.float32) / 255.0#\n",
    "        image = image[None].transpose(0,3,1,2)\n",
    "        #image = image[None].transpose(0,3,1,2)\n",
    "        image = torch.from_numpy(image)\n",
    "        \n",
    "        \n",
    "\n",
    "        batch = {\"image\": np.squeeze(image,0)}\n",
    "        for k in batch:\n",
    "            batch[k] = batch[k] * 2.0 - 1.0\n",
    "\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac383c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "##load the config\n",
    "config_auto = OmegaConf.load(yaml_path)\n",
    "\n",
    "##generate the model from config\n",
    "auto = instantiate_from_config(config_auto.model)\n",
    "\n",
    "##load the state dict\n",
    "auto.load_state_dict(torch.load(ckpt_path, map_location=torch.device('mps'))['state_dict'],strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd29d9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataSet=Image_dataset(512,data_path)\n",
    "loader = DataLoader(\n",
    "    dataSet,\n",
    "    batch_size=1,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11261db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch=next(iter(loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbfd67cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "##using cpu, not gpu\n",
    "output=auto(batch['image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70584da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Original Image\n",
    "original_image=transform(batch['image'][0]*0.5+0.5)\n",
    "\n",
    "##Output Image\n",
    "output_image=transform(output[0][0]*0.5+0.5)\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(8, 4)) \n",
    "\n",
    "# Display each image on a separate subplot\n",
    "axes[0].imshow(original_image)\n",
    "axes[0].set_title('original image')\n",
    "\n",
    "axes[1].imshow(output_image)\n",
    "axes[1].set_title('reconstructed image')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
